{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In the previous lesson, we have learnt how to import data and process them, so that they are ready to be used for the next step in the AI process - Modelling. \n",
    "\n",
    "There are many different types of machine learning techniques which can be used to run different [machine learning tasks](https://developers.google.com/machine-learning/problem-framing/cases) such as classification, regression, and clustering. In this session, we will create our own models to make predictions, cluster data, etc. The skills you will gain here will be used again to create your solution!  \n",
    "\n",
    "## Machine Learning\n",
    "Machine learning refers to the ability of the computer to learn patterns and relationships between data variables. They can do this through previous examples or learning from current datasets. Read this [article](https://hackernoon.com/the-simplest-explanation-of-machine-learning-youll-ever-read-bebc0700047c) to find out more about machine learning. Write down any information that you find interesting in your worksheet.\n",
    "\n",
    "As explored previously, there are 2 main types of machine learning algorithms we want to explore: Supervised learning and unsupervised learning. Do you still remember the [difference between the two](https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithms rely on features and labels\n",
    "# unsupervised learning algorithms does not rely on labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries!\n",
    "Let us first import the pandas library to help us work with our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you used the video sharing site Youtube before? Do you realise that it will recommend videos that it thinks you will like to watch? Do you notice that the videos recommended to you will be different compared to the videos recommended to your friends? How do you think it can do that? \n",
    "\n",
    "The Youtube recommendation technology uses something known as supervised learning techique. Every time you 'like' a video, Youtube will record down the information of the video: Its name, genre, length, uploaders, etc. The more you watch and 'like' videos, the more information will be recorded into the system. \n",
    "\n",
    "This data set will be used to train a supervised learning model which will then predict which video you might like. This is done by analysing the videos you have watched and 'liked', and looking at the similarities between the video information. In this case, the videos that you liked previously will be the features or the data that the model will train. On the other hand, the videos that you most likely will want to watch (watched by other people who liked the same videos as you) will be the labels or the targets to the model/technique. The model/technique essentially tries and \"match\" the features to the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques requires training data that is labelled. For example, in the previous example, a video can either be liked, not rated, or disliked. These are the labels that are necessary in the training data when training the model. With more training data, a more accurate model can be made. \n",
    "\n",
    "Label has to be appropriate. For example, if you want to predict the exam scores of a student given the number of hours spent studying, then the data must contain the exam scores for each student. This will allow the machine learning algorithm to learn from the examples given. \n",
    "\n",
    "Another important term in supervised learning techniques is 'features'. Features refer to the data that can be used to predict the target or label. Based on the example of the exam scores, the exam scores are the target and the number of hours spent studying is a feature. Other features for that example can include the number of questions practiced, amount of sleep before the exam, etc. \n",
    "\n",
    "With the features and labels/targets, the algorithm will then be able to \"learn\" the relationship between the features and labels/targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the articles https://towardsdatascience.com/explaining-supervised-learning-to-a-kid-c2236f423e0f and https://www.geeksforgeeks.org/supervised-unsupervised-learning/, and watch this [video](https://www.youtube.com/watch?v=cfj6yaYE86U) and answer the questions listed below in your worksheet. Pay more attention to supervised learning. It is ok if you do not understand unsupervised learning at this point.\n",
    "\n",
    "- Explain supervised learning in your own words.\n",
    "- Explain and give examples of the terms: features, labels/targets, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques can be used to either classify data into different groups or to predict the relationships between variables. Techniques that classify data return categories or groups. For example, if we want to predict whether there will be rain tomorrow, we can use an algorithm that will return categories such as raining or sunny. On the other hand, techniques that are used for regression return numerical solutions. For example, if we want to predict the amount of rain tomorrow, we can use an alogrithm than will return numbers instead of categories.\n",
    "\n",
    "Read this [article](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/) and watch this [video](https://www.youtube.com/watch?v=f7YB73F0zDo) to find out more information about difference between classification and regression. While reading the article and watching the video, try to think of some scenarios where you will use classification and also some scenarios where you will use regression. List these scenarios in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification is predicting categorical labels, intgers\n",
    "# can be binary classification or multiclass classification\n",
    "\n",
    "# regression is predicting continuous values, can be float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding what is supervised learning, we will now explore the different supervised learning techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the graph! These are the height and weight samples of male and female. Notice how they are grouped together. Males tend to be taller and heavier as compared to females, and you can see that there is a noticeable grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/KNN1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the green dot, the unknown input. Looking at the data, would you say that the unknown input belong to the male data or the female data? Why? How would you determine that?\n",
    "\n",
    "Well, you can see that they are closer to the male data, and thus it is more likely that the unknown data represents a male as well. This method of determining a group by its distance to other, already known data points, is called the K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbours (KNN) can be used in classification or regression problems. However, it is mainly used for classification problems. As the name suggests, this algorithm relies on the surrounding points or neighbours to determine its class or group. For example, if you are trying to classify an unknown point as either class A or class B using KNN and the majority of the points nearest to the unknown point are in class A, which class do you think the unknown point will be in?\n",
    "\n",
    "If you guessed class A, your answer is right. This is because KNN utilises the properties of the majority of the nearest points to decide how to classify unknown points. This is similar to the famous phrase \"birds of the same feather, flock together\". Likewise, you will expect points that are similar to be close to each other.\n",
    "\n",
    "Watch this [video](https://www.youtube.com/watch?v=MDniRwXizWo) to find out more about KNN. What are the main advantages and disadvantages of KNN? You will be using KNN in subsequent exercises. This is because it is an easy to use and flexible algorithm which can be used for many problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#your answer\n",
    "\n",
    "**Advantages of K-Nearest Neighbors (KNN):**\n",
    "\n",
    "Simple and easy to implement: KNN is a simple and straightforward algorithm that requires minimal training, making it easy to implement and understand.\n",
    "No need for a training phase: KNN doesn't require a training phase, unlike other machine learning algorithms such as decision trees or neural networks. This means that KNN can be applied to new data on the fly without the need to retrain the model.\n",
    "Handles multi-class problems well: KNN can handle multi-class classification problems by assigning the class label of the majority of the nearest neighbors to an unknown sample.\n",
    "Can capture non-linear relationships: KNN can capture non-linear relationships between features by using a suitable distance metric.\n",
    "\n",
    "\n",
    "**Disadvantages of K-Nearest Neighbors (KNN):**\n",
    "\n",
    "Computationally expensive: KNN can be computationally expensive, especially for large datasets or high-dimensional data. The time complexity of KNN is O(Nd), where N is the number of samples and d is the number of features.\n",
    "Curse of dimensionality: The curse of dimensionality refers to the fact that the performance of KNN decreases as the number of dimensions increases. This is because as the number of dimensions increases, the distances between samples become more difficult to interpret.\n",
    "Sensitive to irrelevant features: KNN can be sensitive to irrelevant features and the choice of distance metric. This can lead to suboptimal performance and require careful feature selection and normalization.\n",
    "Require good domain knowledge: To effectively use KNN, it's important to have a good understanding of the domain and the relationships between features. This can make it difficult to apply KNN to new domains without significant domain-specific knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding how KNN works, lets try to apply it to a hypothetical scenario. In this scenario, you want to predict if a device is a laptop or a computer using features such as price and amount of memory. As such, you plotted a scatter plot for all the data points that you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/KNN.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis shows the amount of memory (GB) whereas the y-axis shows the price (USD). The blue circles are data points for desktop whereas the orange circles are data points for laptops. The star represents the unknown point.\n",
    "\n",
    "Based on your understanding of KNN, will the unknown point be a desktop or laptop if we were to apply KNN with 3 nearest neighbours? Will your answer change if you were to use 4 nearest neighbours or 5 nearest neighbours? How about if you were to use 9 nearest neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop \n",
    "# answer may change if you were to use more k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you realise that the unknown point will change its classification if you were to use 9 nearest neighbours? From the graph, it is quite obvious that the unknown point is not a desktop. However, due to KNN using the majority, it is possible for KNN to wrongly classify an unknown point if the wrong number of nearest neighbours were used. Thus, it is always important to identify the best number of nearest neighbours. We will see how this is done in the next few workshops when we learn how to tune the models! For now, it is sufficient to just understand why the number of neighbours is an important parameter in K nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying flowers using KNN and the Iris Flower dataset\n",
    "\n",
    "Let us now apply the KNN technique to the Iris Flower dataset. First, load the previously used Iris Flower dataset as a pandas dataframe. Download the file from this [link](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/) if you did not download the dataset previously. The file to download is the iris.data file. You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below for more information. \n",
    "\n",
    "From the photo below, could you explain what is meant by sepal and petal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start by downloading and exploring the dataset!\n",
    "1. Download dataset from website provided\n",
    "2. Open csv file\n",
    "3. print first five rows to check dataset\n",
    "4. add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/iris.data'\n",
    "names = ('sepal length', 'sepal width', 'petal length', 'petal width', 'class')\n",
    "df = pd.read_csv(path, names = names)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data for the KNN algorithm\n",
    "\n",
    "Let us try to use KNN to classify the dataset with the type of flower or class being the target variable. To help us do so, we need to convert the categorical classes into numbers so that it can be understood easier by the computer. We can do so through the usage of label encoding. \n",
    "\n",
    "### Label Encoding\n",
    "Label encoding refers to the assignment of a number for each category. For example, if you have to predict the weather and there are two classes, rainy or sunny, we can label rainy as 0 and sunny as 1 (see table below). In this way, we can convert the categories to numbers.\n",
    "\n",
    "How would you apply label encoding to the iris dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resources/Label2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the class/flower type in the Iris Flower dataset into numbers. What are the different classes within the dataset? How many classes are there in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(df['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           5.1          3.5           1.4          0.2      1\n",
       "1           4.9          3.0           1.4          0.2      1\n",
       "2           4.7          3.2           1.3          0.2      1\n",
       "3           4.6          3.1           1.5          0.2      1\n",
       "4           5.0          3.6           1.4          0.2      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#your answer here\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "mappings = {\n",
    "    'Iris-setosa' : 1,\n",
    "    'Iris-versicolor' : 2,\n",
    "    'Iris-virginica' : 3\n",
    "}\n",
    "\n",
    "df_new = df.copy()\n",
    "\n",
    "df_new['class'] = df_new['class'].map(mappings) # use label encoder in 'class' column \n",
    "\n",
    "display(df_new.head(5))\n",
    "\n",
    "print(np.unique(df_new['class']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, label encode the different classes. 'Iris-setosa' can be 1, 'Iris-versicolor' can be 2 and 'Iris-virginica' can be 3. The code below will encode for one of the classes. Edit the code to encode for all the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Bonus: There is also another method to convert categories to numbers. The method is known as one-hot encoding. One-hot encoding changes the categories into binary (0 or 1) categories. For example, if you have raining or sunny days as categories, one hot encoding will add 2 more columns, rainy and sunny, to the dataframe. If the data point shows rainy, it will be converted to a value of 1 under the raining column and a value of 0 under the sunny column (see table below). Read this [article](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) to find out more about one-hot encoding. Now, read this [article](http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) to learn how to do one-hot encoding for pandas. Import the Iris Flower dataset again as df2 and conduct the one-hot encoding for it.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/Label1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "      <th>class_Iris-setosa</th>\n",
       "      <th>class_Iris-versicolor</th>\n",
       "      <th>class_Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class  \\\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa   \n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa   \n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa   \n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa   \n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa   \n",
       "\n",
       "   class_Iris-setosa  class_Iris-versicolor  class_Iris-virginica  \n",
       "0                1.0                    0.0                   0.0  \n",
       "1                1.0                    0.0                   0.0  \n",
       "2                1.0                    0.0                   0.0  \n",
       "3                1.0                    0.0                   0.0  \n",
       "4                1.0                    0.0                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "df_copy = df.copy()\n",
    "# fit data and transform it\n",
    "one_hot = ohe.fit_transform(df_copy[['class']]).toarray()\n",
    "# Create a dataframe from one hot encoding\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=ohe.get_feature_names(['class']))\n",
    "\n",
    "# concatenate the original dataframe with the one hot encoded df\n",
    "df_one_hot_encoded = pd.concat([df_copy, one_hot_df], axis=1) # axis 1 is columns\n",
    "display(df_one_hot_encoded.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You've learn how to conduct label encoding and one-hot encoding. We can now try out the KNN algorithm. We first have to import the KNN algorithm from scikit learn. [Scikit learn](https://scikit-learn.org/stable/) is an open source python library which contains numerous popular machine learning algorithms. What does scikit learn contain? What can it do? See the listed [examples](https://scikit-learn.org/stable/auto_examples/index.html) for inspiration! Are you brimming with excitement now?\n",
    "\n",
    "\n",
    "Now, try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this [link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to find out how to use the KNeighborsClassifier from sklearn. Do you remember from earlier in this notebook that the number of neighbours is required for KNN? From the link, what is the default number of neighbors used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the default number of neighbors to try and classify the Iris Flower dataset. \n",
    "\n",
    "We will only use 2 features (sepal_length and sepal_width) initially. In the code below, these are included in the 'x' dataframe. The 'class' of the flower i.e. the name of the flower species will be the 'label', included in the 'y' dataframe. \n",
    "\n",
    "Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           5.1          3.5           1.4          0.2      1\n",
       "1           4.9          3.0           1.4          0.2      1\n",
       "2           4.7          3.2           1.3          0.2      1\n",
       "3           4.6          3.1           1.5          0.2      1\n",
       "4           5.0          3.6           1.4          0.2      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_new.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- sepal_length\n",
      "- sepal_width\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- sepal length\n",
      "- sepal width\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df_new[['sepal length','sepal width']]\n",
    "y = df_new['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "#print(x.head())\n",
    "#print(y.head())\n",
    "\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [3]\n",
    "test['sepal_width'] = [5]\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(f'Predicted class: {predict_flower}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, do you know which flower type was predicted for a data point with sepal length = 5 and sepal width = 3? Remember our encoding earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! What if the sepal length = 3 and sepal width = 5? Edit the code above to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have trained your first supervised learning model. However, we only used 2 variables. Train another KNN model named KNN2 with all the other variables ('sepal_length','sepal_width','petal_length','petal_width') instead of just sepal length and sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  class\n",
       "0             5.1          3.5           1.4          0.2      1\n",
       "1             4.9          3.0           1.4          0.2      1\n",
       "2             4.7          3.2           1.3          0.2      1\n",
       "3             4.6          3.1           1.5          0.2      1\n",
       "4             5.0          3.6           1.4          0.2      1\n",
       "..            ...          ...           ...          ...    ...\n",
       "145           6.7          3.0           5.2          2.3      3\n",
       "146           6.3          2.5           5.0          1.9      3\n",
       "147           6.5          3.0           5.2          2.0      3\n",
       "148           6.2          3.4           5.4          2.3      3\n",
       "149           5.9          3.0           5.1          1.8      3\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- petal_length\n",
      "- petal_width\n",
      "- sepal_length\n",
      "- sepal_width\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- petal length\n",
      "- petal width\n",
      "- sepal length\n",
      "- sepal width\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x = df_new.drop(columns=['class']).copy()\n",
    "y = df_new['class'].copy()\n",
    "\n",
    "KNN2 = KNeighborsClassifier()\n",
    "KNN2 = KNN2.fit(x, y)\n",
    "\n",
    "test2 = pd.DataFrame()\n",
    "test2['sepal_length'] = [3]\n",
    "test2['sepal_width'] = [5]\n",
    "test2['petal_length'] = [5]\n",
    "test2['petal_width'] = [3]\n",
    "\n",
    "predict_flower_KNN2 = KNN2.predict(test2)\n",
    "print(f'Predicted class: {predict_flower_KNN2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your new model, can you predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- petal_length\n",
      "- petal_width\n",
      "- sepal_length\n",
      "- sepal_width\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- petal length\n",
      "- petal width\n",
      "- sepal length\n",
      "- sepal width\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "test3 = pd.DataFrame()\n",
    "test3['sepal_length'] = [5.8]\n",
    "test3['sepal_width'] = [2.3]\n",
    "test3['petal_length'] = [5.0]\n",
    "test3['petal_width'] = [1.3]\n",
    "\n",
    "predict_flower_KNN2 = KNN2.predict(test3)\n",
    "print(f'Predicted class: {predict_flower_KNN2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 2 , Iris-versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You have used the k-nearest neighbour algorithm to train a classification model that can classify the types of flower given the characteristics of the flowers such as the sepal length, sepal width , petal length , and the petal width. \n",
    "\n",
    "How would this kind of models be useful? Write down your answer below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This models is useful for dataset not too huge and the\n",
    "# problem should be simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How else do you think the k-nearest neighbour algorithm can be used? Write down your answer below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to do regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many models that can be used for classification. Next, we will explore the decision tree to help us with classification as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another supervised machine learning technique is the decision tree. Watch this [video](https://www.youtube.com/watch?v=eKD5gxPPeY00) to find out more about decision trees. After watching, draw an example of a decision tree in your worksheet. You can refer to the example shown below.\n",
    "\n",
    "We make numerous decisions every day. How do you make certain decisions? What kind of decision tree will you draw? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/dt1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another supervised machine learning technique is the decision tree. Watch this [video](https://www.youtube.com/watch?v=eKD5gxPPeY00) to find out more about decision trees. After watching, draw an example of a decision tree in your worksheet. You can refer to the example shown below.\n",
    "\n",
    "We make numerous decisions every day. How do you make certain decisions? What kind of decision tree will you draw? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import the decision tree from scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the same df dataframe from earlier in this notebook. The df dataframe contains the Iris Flower dataset and the outputs have been label encoded. We will first use the sepal length and sepal width as x values and the class as the targets/outputs or y values. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the Decision Tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df_new[['sepal length','sepal width']]\n",
    "y = df_new['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "#print(x.head())\n",
    "#print(y.head())\n",
    "\n",
    "# Train decision tree using the x and y values. This is done through the .fit method.\n",
    "dt = dt.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the initialisation code. Why do we use the DecisionTreeClassifier instead of the DecisionTreeRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we can solving a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you make a prediction using the trained tree? Can you predict the type of flower if its sepal length = 5 and sepal_width = 3? You can use the .predict method to do so. Edit the code below to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- sepal_length\n",
      "- sepal_width\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- sepal length\n",
      "- sepal width\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe called test2 with sepal_length and sepal_width as its columns. Sepal_length has been done for you in the code below.\n",
    "test4 = pd.DataFrame()\n",
    "test4['sepal_length'] = [5]\n",
    "test4['sepal_width'] = [3]\n",
    "\n",
    "\n",
    "# Use the .predict method to predict the new flower. You can call the predicted flower as predict_flower.\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the predicted flower type and does it match with that predicted by K nearest neighbours earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a new decision tree, dt2, based on sepal length, sepal width, petal length and petal width. Predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = tree.DecisionTreeClassifier()\n",
    "\n",
    "x = df_new.drop(columns=['class']).copy()\n",
    "y = df_new['class'].copy()\n",
    "dt2 = dt2.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 = pd.DataFrame()\n",
    "test5['sepal_length'] = [5.8]\n",
    "test5['sepal_width'] = [2.3]\n",
    "test5['petal_length'] = [5.0]\n",
    "test5['petal_width'] = [1.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted flower: [3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ITE/lib/python3.7/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- petal_length\n",
      "- petal_width\n",
      "- sepal_length\n",
      "- sepal_width\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- petal length\n",
      "- petal width\n",
      "- sepal length\n",
      "- sepal width\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "predicted_flower = dt2.predict(test5)\n",
    "print(f'Predicted flower: {predicted_flower}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the flower type predicted by the new tree? Is it the same as that predicted by K-Nearest Neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. It predicted class 3 while KNN predicted class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can see that while most machine learning techniques may be used to solve the same problem, the outcome/predictions may differ across models! As such, there is a need to choose which models to use based on the accuracy of the models. You will learn how to evaluate the quality of the models in the later workshops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITE",
   "language": "python",
   "name": "ite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
